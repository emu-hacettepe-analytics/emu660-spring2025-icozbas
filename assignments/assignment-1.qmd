---
title: "Assignment 1"
---

My first assignment has two parts.

## (a) [Veri Bilimi ve Endüstri Mühendisliği Üzerine Sohbetler - Cem Vardar & Erdi Dasdemir](https://www.youtube.com/watch?v=Fi8-phj1X1A)

Mr. Vardar, an experienced industrial engineer and data scientist, discusses how data science and industrial engineering integrated with each other, emphasizing that data analytics is a key problem-solving tool.

He highlights that simple solutions are often the most effective in complex systems. While complexity may be necessary, solutions should start with a structured, simple approach.

Mr. Vardar also explains various data science roles, their responsibilities, and the essential skills needed in the field. He introduces the Pareto Principle (80-20 rule), suggesting that learning just 20% of key skills (like SQL, programming, and data visualization) can meet 80% of an industrial engineer’s needs.

The talk concludes with career advice, book recommendations, and an interactive Q&A session on industry trends and best practices.

## (b) Explore Statistical Summaries with Custom Functions and Iteration Methods

```{r}
compute_stats <- function(x) {
  
  if (!is.numeric(x)) {
    stop("Input must be a numeric vector.")
  }
  
  stats <- list(
    mean = mean(x, na.rm = TRUE),
    median = median(x, na.rm = TRUE),
    variance = var(x, na.rm = TRUE),
    IQR = IQR(x, na.rm = TRUE),
    minimum = min(x, na.rm = TRUE),
    maximum = max(x, na.rm = TRUE)
  )
  
  return(stats)
}

data(mtcars)
compute_stats(mtcars$mpg)

for (col in names(mtcars)) {

  if (is.numeric(mtcars[[col]])) {
    cat("Statistics for", col, ":\n")
    stats <- compute_stats(mtcars[[col]])
    print(stats)
    cat("\n")
  }
}

stats_list <- sapply(mtcars, function(col) {
  if (is.numeric(col)) {
    compute_stats(col)
  }
})

stats_list
```

## (c) Load the “na_example” dataset from the dslabs package

```{r}
library(dslabs)

data(na_example)

print(na_example)

na_count <- sum(is.na(na_example))
na_positions <- which(is.na(na_example), arr.ind = TRUE)

print(na_count)
print(na_positions)

mean_original <- mean(na_example, na.rm = TRUE)
sd_original <- sd(na_example, na.rm = TRUE)

print(mean_original)
print(sd_original)

na_example_version1 <- na_example
na_example_version1[is.na(na_example_version1)] <- median(na_example_version1, na.rm = TRUE)

na_example_version2 <- na_example
non_na_values <- na_example[!is.na(na_example)]
set.seed(123)
na_example_version2[is.na(na_example_version2)] <- sample(non_na_values, size = sum(is.na(na_example_version2)), replace = TRUE)

mean_version1 <- mean(na_example_version1, na.rm = TRUE)
sd_version1 <- sd(na_example_version1, na.rm = TRUE)

mean_version2 <- mean(na_example_version2, na.rm = TRUE)
sd_version2 <- sd(na_example_version2, na.rm = TRUE)

print(mean_version1)
print(sd_version1)

print(mean_version2)
print(sd_version2)
```

In both versions where we imputed the missing data, an improvement in the standard deviation was observed. However, we found that the first version, where we added the median, provided more consistent results.
